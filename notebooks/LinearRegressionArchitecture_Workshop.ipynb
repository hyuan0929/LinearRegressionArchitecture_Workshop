{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1a1d70",
   "metadata": {},
   "source": [
    "# üè° Linear Regression Architecture Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cb630",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the **Linear Regression Architecture Workshop**.  \n",
    "This workshop is designed for college-level students learning both:\n",
    "\n",
    "1. **Univariate Linear Regression** ‚Äì a foundational algorithm in Machine Learning, focusing on predicting continuous values from a single feature.  \n",
    "2. **Machine Learning Operations (MLOps)** ‚Äì design patterns and architectural considerations that make machine learning experiments reproducible, scalable, and production-ready.  \n",
    "\n",
    "We will use **real-world housing price data** from **California (USA)** and **Ontario (Canada)** as our case study.  \n",
    "The goal is to not only understand how Linear Regression works, but also how to **design and implement a machine learning project** from sourcing data ‚Üí building models ‚Üí structuring code ‚Üí preparing for deployment.  \n",
    "\n",
    "The workshop will be completed in **two 2-hour sessions**, with **homework assignments** to be completed before each class.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b35c90",
   "metadata": {},
   "source": [
    "## Workshop Structure\n",
    "\n",
    "### üìö Session 1 ‚Äì Univariate Linear Regression\n",
    "- **Lecture focus**: Mathematical intuition, model formulation, gradient descent, cost function, evaluation metrics.  \n",
    "- **Practical focus**: Implementing Univariate Linear Regression from scratch + using `scikit-learn`.  \n",
    "- **Homework before class**: Data sourcing (from CSV, APIs, and relational databases).  \n",
    "\n",
    "### ‚öôÔ∏è Session 2 ‚Äì Machine Learning Operations (MLOps)\n",
    "- **Lecture focus**: Code modularity, reproducibility, experiment tracking, design patterns in ML architecture.  \n",
    "- **Practical focus**: Architecting the project with pipelines, config management, and modular scripts.  \n",
    "- **Homework before class**: Refactor previous Linear Regression code into modular, production-ready format.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cb510",
   "metadata": {},
   "source": [
    "## Instructions for Students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716f1b2",
   "metadata": {},
   "source": [
    "### üîπ Before Session 1: Data Sourcing\n",
    "\n",
    "Your first task is to collect **housing price data** for California and Ontario.  \n",
    "You must experiment with **at least three different types of data sources**:\n",
    "\n",
    "1. **CSV Files**  \n",
    "   - Find open housing datasets (e.g., Kaggle, UCI ML Repository, government portals).  \n",
    "   - Example: [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset).  \n",
    "   - Save datasets in `data/raw/` folder.  \n",
    "\n",
    "2. **Web Services (APIs)**  \n",
    "   - Explore free APIs offering housing, rental, or real-estate data.  \n",
    "   - Example APIs:  \n",
    "     - [Zillow (unofficial APIs exist, check docs)]  \n",
    "     - [Realtor.ca data endpoints]  \n",
    "     - [City of Toronto Open Data API](https://open.toronto.ca/)  \n",
    "     - [California State Open Data Portal](https://data.ca.gov/).  \n",
    "   - Use Python packages like `requests` or `httpx` to fetch data.  \n",
    "   - Save results into structured JSON or convert to DataFrames.  \n",
    "\n",
    "3. **Relational Databases**  \n",
    "   - Connect to a **PostgreSQL** or **MySQL** demo database.  \n",
    "   - Option 1: Use hosted databases with sample housing/economic data.  \n",
    "   - Option 2: Load CSVs into a local database (e.g., PostgreSQL with `psql` or SQLite for portability).  \n",
    "   - Connect from Python using `sqlalchemy` or `psycopg2`.  \n",
    "   - Run SQL queries to filter/select data.  \n",
    "\n",
    "üí° **Deliverable before Session 1**:  \n",
    "- A Jupyter Notebook that loads housing price data from all three sources (CSV, API, Database) and explores it with basic descriptive statistics and plots.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49cefb",
   "metadata": {},
   "source": [
    "### üîπ During Session 1: Univariate Linear Regression Experiment\n",
    "\n",
    "1. **Define the Problem**  \n",
    "   - Select one feature (e.g., median income, number of rooms, lot size) to predict housing price.  \n",
    "\n",
    "2. **Preprocess Data**  \n",
    "   - Handle missing values.  \n",
    "   - Normalize/standardize features.  \n",
    "   - Split data into **train/test sets**.  \n",
    "\n",
    "3. **Model Implementation**  \n",
    "   - Implement Linear Regression **from scratch**:  \n",
    "     - Hypothesis function $ h_\\theta(x) = \\theta_0 + \\theta_1 x $  \n",
    "     - Cost function (MSE)  \n",
    "     - Gradient descent update rule  \n",
    "   - Implement Linear Regression **using scikit-learn** for comparison.  \n",
    "\n",
    "4. **Model Evaluation**  \n",
    "   - Compute RMSE, MAE, and $ R^2 $ score.  \n",
    "   - Visualize regression line vs. data points.  \n",
    "\n",
    "üí° **Deliverable during Session 1**:  \n",
    "- A working notebook with both a manual and `scikit-learn` Linear Regression implementation.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51def6",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "MeanValue and MaxValue was selected as the independent variable and WorkPeriod as the dependent variable.\n",
    "The number of rooms is a fundamental housing characteristic with a clear and interpretable relationship to price. Using this feature supports the assumptions of univariate linear regression and keeps the model simple and easy to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187a18b",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Import the data from Neon database\n",
    "\n",
    "Connect String: postgresql://neondb_owner:npg_Sh8bV3HjZvkd@ep-plain-scene-ahmzh8by-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require\n",
    "\n",
    "Table: robot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d1bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported table 'robot_data' to data/raw/RMBR4-2_export_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# If the notebook is inside notebooks/, go back to project root\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n",
    "# Load config\n",
    "with open(\"configs/experiment_config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "from src.db_export import export_postgres_table_to_csv\n",
    "\n",
    "# Read database config\n",
    "connstr = config[\"database\"][\"connstr\"]\n",
    "table_name = config[\"database\"][\"source_table\"]\n",
    "\n",
    "# Read output path from config\n",
    "output_csv = config[\"paths\"][\"raw_csv\"]\n",
    "\n",
    "# Export data from Neon PostgreSQL to CSV\n",
    "export_postgres_table_to_csv(\n",
    "    connstr=connstr,\n",
    "    table_name=table_name,\n",
    "    output_csv=output_csv,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3dbad5",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77561c09",
   "metadata": {},
   "source": [
    "Using the force values measured on each robot axis, I will analyze the robot‚Äôs time-series data, which consists of work periods and rest periods. The goal is to segment the data into work/rest periods based on the force signal. Each identified work period is assigned a sequential index, and this work-period number is used as the independent variable. For each work period, the mean force and peak force within that period are computed as the dependent variables.\n",
    "\n",
    "Next, I group the work periods into detection intervals, where each interval contains 10 consecutive work periods. Within each detection interval, I run regression analysis on the dependent variables over the work-period index:\n",
    "\n",
    "If the mean force shows a statistically significant upward trend, it suggests the robot may be experiencing system aging or gradual degradation.\n",
    "\n",
    "If the peak force shows a statistically significant upward trend, it suggests the robot may be at risk of an urgent or imminent failure.\n",
    "\n",
    "The raw dataset is located at:\n",
    "data/raw/RMBR4-2_export_test.csv\n",
    "\n",
    "I will transform it into a summarized table with the following fields:\n",
    "\n",
    "work_period\n",
    "\n",
    "mean_value\n",
    "\n",
    "peak_value\n",
    "\n",
    "interval_start_time (start time of the first work period in the interval)\n",
    "\n",
    "interval_end_time (end time of the last work period in the interval)\n",
    "\n",
    "Finally, I will export the resulting table to:\n",
    "data/raw/RMBR4-2_export_test_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00a6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 1 done. Saved period summary to: data/raw/RMBR4-2_export_test_1.csv\n",
      "Period rows: 858\n",
      "\n",
      "üìå Period CSV columns:\n",
      "['work_period', 'mean_value', 'peak_value', 'period_start_time', 'period_end_time']\n",
      "\n",
      "üìå First 5 rows of period summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_period</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>peak_value</th>\n",
       "      <th>period_start_time</th>\n",
       "      <th>period_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.302866</td>\n",
       "      <td>8.908955</td>\n",
       "      <td>2022-10-17 12:19:22.005000+00:00</td>\n",
       "      <td>2022-10-17 12:19:55.136000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.449832</td>\n",
       "      <td>6.300471</td>\n",
       "      <td>2022-10-17 12:20:56.771000+00:00</td>\n",
       "      <td>2022-10-17 12:21:31.056000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.491427</td>\n",
       "      <td>6.707684</td>\n",
       "      <td>2022-10-17 12:21:46.588000+00:00</td>\n",
       "      <td>2022-10-17 12:22:21.050000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.255471</td>\n",
       "      <td>5.874910</td>\n",
       "      <td>2022-10-17 12:22:45.266000+00:00</td>\n",
       "      <td>2022-10-17 12:23:17.894000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.881057</td>\n",
       "      <td>6.632019</td>\n",
       "      <td>2022-10-17 12:23:49.839000+00:00</td>\n",
       "      <td>2022-10-17 12:24:22.332000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_period  mean_value  peak_value                period_start_time  \\\n",
       "0            1    3.302866    8.908955 2022-10-17 12:19:22.005000+00:00   \n",
       "1            2    3.449832    6.300471 2022-10-17 12:20:56.771000+00:00   \n",
       "2            3    3.491427    6.707684 2022-10-17 12:21:46.588000+00:00   \n",
       "3            4    3.255471    5.874910 2022-10-17 12:22:45.266000+00:00   \n",
       "4            5    2.881057    6.632019 2022-10-17 12:23:49.839000+00:00   \n",
       "\n",
       "                   period_end_time  \n",
       "0 2022-10-17 12:19:55.136000+00:00  \n",
       "1 2022-10-17 12:21:31.056000+00:00  \n",
       "2 2022-10-17 12:22:21.050000+00:00  \n",
       "3 2022-10-17 12:23:17.894000+00:00  \n",
       "4 2022-10-17 12:24:22.332000+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Step 1: Build work-period summary from raw time-series data\n",
    "# raw_csv -> period_csv\n",
    "# ------------------------------------------------------------\n",
    "from src.preprocessing import run_preprocessing_pipeline\n",
    "period_df, _preprocessed_df = run_preprocessing_pipeline(config)\n",
    "\n",
    "print(\"‚úÖ Step 1 done. Saved period summary to:\", config[\"paths\"][\"period_csv\"])\n",
    "print(\"Period rows:\", len(period_df))\n",
    "\n",
    "# ---- Inspect result ----\n",
    "print(\"\\nüìå Period CSV columns:\")\n",
    "print(period_df.columns.tolist())\n",
    "\n",
    "print(\"\\nüìå First 5 rows of period summary:\")\n",
    "display(period_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfc179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 2 done.\n",
      " - TRAIN: data/preprocessed/RMBR4-2_export_preprocessed_train.csv\n",
      " - TEST : data/preprocessed/RMBR4-2_export_preprocessed_test.csv\n",
      "\n",
      "üìå TRAIN columns:\n",
      "['work_period', 'mean_value', 'peak_value', 'period_start_time', 'period_end_time', 'interval_id', 'mean_value_z', 'peak_value_z']\n",
      "\n",
      "üìå TRAIN first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_period</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>peak_value</th>\n",
       "      <th>period_start_time</th>\n",
       "      <th>period_end_time</th>\n",
       "      <th>interval_id</th>\n",
       "      <th>mean_value_z</th>\n",
       "      <th>peak_value_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>3.586541</td>\n",
       "      <td>8.039739</td>\n",
       "      <td>2022-10-17 12:35:51.838000+00:00</td>\n",
       "      <td>2022-10-17 12:36:25.716000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979374</td>\n",
       "      <td>0.741561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>3.764583</td>\n",
       "      <td>7.634454</td>\n",
       "      <td>2022-10-17 12:36:48.315000+00:00</td>\n",
       "      <td>2022-10-17 12:37:23.086000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.565188</td>\n",
       "      <td>0.409189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2.908206</td>\n",
       "      <td>6.261834</td>\n",
       "      <td>2022-10-17 12:38:03.164000+00:00</td>\n",
       "      <td>2022-10-17 12:38:32.099000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.252553</td>\n",
       "      <td>-0.716489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>3.188224</td>\n",
       "      <td>6.185474</td>\n",
       "      <td>2022-10-17 12:44:50.740000+00:00</td>\n",
       "      <td>2022-10-17 12:45:25.360000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.331209</td>\n",
       "      <td>-0.779112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>3.479667</td>\n",
       "      <td>6.995066</td>\n",
       "      <td>2022-10-17 12:45:46.216000+00:00</td>\n",
       "      <td>2022-10-17 12:46:19.107000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.627726</td>\n",
       "      <td>-0.115170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_period  mean_value  peak_value                 period_start_time  \\\n",
       "0           11    3.586541    8.039739  2022-10-17 12:35:51.838000+00:00   \n",
       "1           12    3.764583    7.634454  2022-10-17 12:36:48.315000+00:00   \n",
       "2           13    2.908206    6.261834  2022-10-17 12:38:03.164000+00:00   \n",
       "3           14    3.188224    6.185474  2022-10-17 12:44:50.740000+00:00   \n",
       "4           15    3.479667    6.995066  2022-10-17 12:45:46.216000+00:00   \n",
       "\n",
       "                    period_end_time  interval_id  mean_value_z  peak_value_z  \n",
       "0  2022-10-17 12:36:25.716000+00:00            2      0.979374      0.741561  \n",
       "1  2022-10-17 12:37:23.086000+00:00            2      1.565188      0.409189  \n",
       "2  2022-10-17 12:38:32.099000+00:00            2     -1.252553     -0.716489  \n",
       "3  2022-10-17 12:45:25.360000+00:00            2     -0.331209     -0.779112  \n",
       "4  2022-10-17 12:46:19.107000+00:00            2      0.627726     -0.115170  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå TEST columns:\n",
      "['work_period', 'mean_value', 'peak_value', 'period_start_time', 'period_end_time', 'interval_id', 'mean_value_z', 'peak_value_z']\n",
      "\n",
      "üìå TEST first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_period</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>peak_value</th>\n",
       "      <th>period_start_time</th>\n",
       "      <th>period_end_time</th>\n",
       "      <th>interval_id</th>\n",
       "      <th>mean_value_z</th>\n",
       "      <th>peak_value_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.302866</td>\n",
       "      <td>8.908955</td>\n",
       "      <td>2022-10-17 12:19:22.005000+00:00</td>\n",
       "      <td>2022-10-17 12:19:55.136000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>1.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.449832</td>\n",
       "      <td>6.300471</td>\n",
       "      <td>2022-10-17 12:20:56.771000+00:00</td>\n",
       "      <td>2022-10-17 12:21:31.056000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529560</td>\n",
       "      <td>-0.684803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.491427</td>\n",
       "      <td>6.707684</td>\n",
       "      <td>2022-10-17 12:21:46.588000+00:00</td>\n",
       "      <td>2022-10-17 12:22:21.050000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666422</td>\n",
       "      <td>-0.350850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.255471</td>\n",
       "      <td>5.874910</td>\n",
       "      <td>2022-10-17 12:22:45.266000+00:00</td>\n",
       "      <td>2022-10-17 12:23:17.894000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109944</td>\n",
       "      <td>-1.033803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.881057</td>\n",
       "      <td>6.632019</td>\n",
       "      <td>2022-10-17 12:23:49.839000+00:00</td>\n",
       "      <td>2022-10-17 12:24:22.332000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.341881</td>\n",
       "      <td>-0.412903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_period  mean_value  peak_value                 period_start_time  \\\n",
       "0            1    3.302866    8.908955  2022-10-17 12:19:22.005000+00:00   \n",
       "1            2    3.449832    6.300471  2022-10-17 12:20:56.771000+00:00   \n",
       "2            3    3.491427    6.707684  2022-10-17 12:21:46.588000+00:00   \n",
       "3            4    3.255471    5.874910  2022-10-17 12:22:45.266000+00:00   \n",
       "4            5    2.881057    6.632019  2022-10-17 12:23:49.839000+00:00   \n",
       "\n",
       "                    period_end_time  interval_id  mean_value_z  peak_value_z  \n",
       "0  2022-10-17 12:19:55.136000+00:00            1      0.046000      1.454400  \n",
       "1  2022-10-17 12:21:31.056000+00:00            1      0.529560     -0.684803  \n",
       "2  2022-10-17 12:22:21.050000+00:00            1      0.666422     -0.350850  \n",
       "3  2022-10-17 12:23:17.894000+00:00            1     -0.109944     -1.033803  \n",
       "4  2022-10-17 12:24:22.332000+00:00            1     -1.341881     -0.412903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Step 2: Split the period-level table into TRAIN/TEST\n",
    "# period_csv -> preprocessed_train_csv & preprocessed_test_csv\n",
    "# (Optional) creates mean_value_z / peak_value_z using TRAIN stats\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "from src.splitter import split_period_csv_to_train_test\n",
    "\n",
    "out = split_period_csv_to_train_test(config)\n",
    "\n",
    "print(\"‚úÖ Step 2 done.\")\n",
    "print(\" - TRAIN:\", out[\"preprocessed_train_csv\"])\n",
    "print(\" - TEST :\", out[\"preprocessed_test_csv\"])\n",
    "\n",
    "train_df = pd.read_csv(out[\"preprocessed_train_csv\"])\n",
    "test_df  = pd.read_csv(out[\"preprocessed_test_csv\"])\n",
    "\n",
    "# ---- Inspect TRAIN ----\n",
    "print(\"\\nüìå TRAIN columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nüìå TRAIN first 5 rows:\")\n",
    "display(train_df.head())\n",
    "\n",
    "# ---- Inspect TEST ----\n",
    "print(\"\\nüìå TEST columns:\")\n",
    "print(test_df.columns.tolist())\n",
    "\n",
    "print(\"\\nüìå TEST first 5 rows:\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53115440",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "\n",
    "Input: data/preprocessed/RMBR4-2_export_preprocessed_train.csv\n",
    "\n",
    "For each detection interval (interval_id), perform linear regression using:\n",
    "\n",
    "Independent variable (X): work_period\n",
    "\n",
    "Dependent variables (y): mean_value_z and peak_value_z\n",
    "\n",
    "Apply two implementations for comparison:\n",
    "\n",
    "From scratch (gradient descent): estimate theta0 and theta1\n",
    "\n",
    "scikit-learn: estimate theta0 and theta1\n",
    "\n",
    "Aggregate the results into a new table keyed by interval_id, with one row per interval.\n",
    "\n",
    "Output: data/models/interval_theta_table.csv\n",
    "\n",
    "Note: Each interval yields two sets of parameters (mean and peak), producing eight parameter columns:\n",
    "\n",
    "scratch_mean_theta0, scratch_mean_theta1\n",
    "\n",
    "scratch_peak_theta0, scratch_peak_theta1\n",
    "\n",
    "sklearn_mean_theta0, sklearn_mean_theta1\n",
    "\n",
    "sklearn_peak_theta0, sklearn_peak_theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59466701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 3 done (TRAIN only).\n",
      " - Input : data/preprocessed/RMBR4-2_export_preprocessed_train.csv\n",
      " - Output: data/models/interval_theta_table.csv\n",
      "\n",
      "üìå interval_theta_table columns:\n",
      "['interval_id', 'start_work_period', 'end_work_period', 'n_periods', 'scratch_mean_theta0', 'scratch_mean_theta1', 'scratch_peak_theta0', 'scratch_peak_theta1', 'sklearn_mean_theta0', 'sklearn_mean_theta1', 'sklearn_peak_theta0', 'sklearn_peak_theta1', 'learning_rate', 'iterations', 'target_space']\n",
      "\n",
      "üìå interval_theta_table first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_id</th>\n",
       "      <th>start_work_period</th>\n",
       "      <th>end_work_period</th>\n",
       "      <th>n_periods</th>\n",
       "      <th>scratch_mean_theta0</th>\n",
       "      <th>scratch_mean_theta1</th>\n",
       "      <th>scratch_peak_theta0</th>\n",
       "      <th>scratch_peak_theta1</th>\n",
       "      <th>sklearn_mean_theta0</th>\n",
       "      <th>sklearn_mean_theta1</th>\n",
       "      <th>sklearn_peak_theta0</th>\n",
       "      <th>sklearn_peak_theta1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>iterations</th>\n",
       "      <th>target_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.890499</td>\n",
       "      <td>0.100110</td>\n",
       "      <td>-0.975986</td>\n",
       "      <td>0.075420</td>\n",
       "      <td>-0.890499</td>\n",
       "      <td>0.100110</td>\n",
       "      <td>-0.975986</td>\n",
       "      <td>0.075420</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3000</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>3.687289</td>\n",
       "      <td>-0.092567</td>\n",
       "      <td>5.146264</td>\n",
       "      <td>-0.128380</td>\n",
       "      <td>3.687289</td>\n",
       "      <td>-0.092567</td>\n",
       "      <td>5.146264</td>\n",
       "      <td>-0.128380</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3000</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.934994</td>\n",
       "      <td>0.149576</td>\n",
       "      <td>-6.466034</td>\n",
       "      <td>0.124693</td>\n",
       "      <td>-7.934994</td>\n",
       "      <td>0.149576</td>\n",
       "      <td>-6.466034</td>\n",
       "      <td>0.124693</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3000</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.381330</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>-3.109910</td>\n",
       "      <td>0.051936</td>\n",
       "      <td>-1.381330</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>-3.109910</td>\n",
       "      <td>0.051936</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3000</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>8.836954</td>\n",
       "      <td>-0.118015</td>\n",
       "      <td>15.307592</td>\n",
       "      <td>-0.196919</td>\n",
       "      <td>8.836954</td>\n",
       "      <td>-0.118015</td>\n",
       "      <td>15.307592</td>\n",
       "      <td>-0.196919</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3000</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   interval_id  start_work_period  end_work_period  n_periods  \\\n",
       "0            2                 11               20         10   \n",
       "1            4                 31               40         10   \n",
       "2            6                 51               60         10   \n",
       "3            7                 61               70         10   \n",
       "4            8                 71               80         10   \n",
       "\n",
       "   scratch_mean_theta0  scratch_mean_theta1  scratch_peak_theta0  \\\n",
       "0            -0.890499             0.100110            -0.975986   \n",
       "1             3.687289            -0.092567             5.146264   \n",
       "2            -7.934994             0.149576            -6.466034   \n",
       "3            -1.381330             0.026113            -3.109910   \n",
       "4             8.836954            -0.118015            15.307592   \n",
       "\n",
       "   scratch_peak_theta1  sklearn_mean_theta0  sklearn_mean_theta1  \\\n",
       "0             0.075420            -0.890499             0.100110   \n",
       "1            -0.128380             3.687289            -0.092567   \n",
       "2             0.124693            -7.934994             0.149576   \n",
       "3             0.051936            -1.381330             0.026113   \n",
       "4            -0.196919             8.836954            -0.118015   \n",
       "\n",
       "   sklearn_peak_theta0  sklearn_peak_theta1  learning_rate  iterations  \\\n",
       "0            -0.975986             0.075420           0.05        3000   \n",
       "1             5.146264            -0.128380           0.05        3000   \n",
       "2            -6.466034             0.124693           0.05        3000   \n",
       "3            -3.109910             0.051936           0.05        3000   \n",
       "4            15.307592            -0.196919           0.05        3000   \n",
       "\n",
       "  target_space  \n",
       "0            z  \n",
       "1            z  \n",
       "2            z  \n",
       "3            z  \n",
       "4            z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Step 3: Model Implementation (TRAIN only)\n",
    "# For each interval_id, fit linear regression:\n",
    "#   X = work_period\n",
    "#   y = mean_value_z and peak_value_z\n",
    "# Two implementations:\n",
    "#   (1) From scratch (Gradient Descent) -> theta0, theta1\n",
    "#   (2) scikit-learn LinearRegression   -> theta0, theta1\n",
    "# Output:\n",
    "#   data/models/interval_theta_table.csv\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# If the notebook is inside /notebooks, go one level up to project root\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Load config\n",
    "with open(\"configs/experiment_config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# IMPORTANT: Train-only input\n",
    "# Your model.py reads config[\"paths\"][\"preprocessed_train_csv\"]\n",
    "# and writes config[\"paths\"][\"theta_table_csv\"]\n",
    "from src.model import build_interval_theta_table\n",
    "\n",
    "theta_df = build_interval_theta_table(config)\n",
    "\n",
    "print(\"‚úÖ Step 3 done (TRAIN only).\")\n",
    "print(\" - Input :\", config[\"paths\"][\"preprocessed_train_csv\"])\n",
    "print(\" - Output:\", config[\"paths\"][\"theta_table_csv\"])\n",
    "\n",
    "# Inspect result\n",
    "print(\"\\nüìå interval_theta_table columns:\")\n",
    "print(theta_df.columns.tolist())\n",
    "\n",
    "print(\"\\nüìå interval_theta_table first 5 rows:\")\n",
    "display(theta_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41ebb0",
   "metadata": {},
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6404ead",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "In this step, the performance of the linear regression models is evaluated **using the training dataset only**, in order to assess how well the models fit the historical data without introducing information from the test set.\n",
    "\n",
    "For each detection interval (`interval_id`), linear regression models are evaluated with:\n",
    "\n",
    "- **Independent variable (X):** work period index (`work_period`)\n",
    "- **Dependent variables (y):**\n",
    "  - `mean_value_z` (average force, indicating long-term system aging)\n",
    "  - `peak_value_z` (peak force, indicating potential imminent failure)\n",
    "\n",
    "Two regression approaches are compared:\n",
    "\n",
    "1. **From-scratch linear regression**, implemented using gradient descent.\n",
    "2. **scikit-learn linear regression**, used as a reference implementation.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "For each interval and each dependent variable, the following metrics are computed:\n",
    "\n",
    "- **Root Mean Squared Error (RMSE):** measures the overall prediction error magnitude.\n",
    "- **Mean Absolute Error (MAE):** measures the average absolute deviation between predictions and true values.\n",
    "- **Coefficient of Determination (R¬≤):** measures the proportion of variance explained by the model.\n",
    "\n",
    "These metrics provide a quantitative comparison between the manually implemented model and the scikit-learn implementation.\n",
    "\n",
    "### Visualization\n",
    "\n",
    "To further support the evaluation, regression results are visualized for each detection interval:\n",
    "\n",
    "- The original data points are plotted as scatter points.\n",
    "- The regression line obtained from the **from-scratch implementation** is plotted as a solid line.\n",
    "- The regression line obtained from the **scikit-learn implementation** is plotted as a dashed line.\n",
    "\n",
    "These plots allow for a qualitative comparison of the two models and help verify that the gradient descent implementation converges to a similar solution as the scikit-learn model.\n",
    "\n",
    "### Output Artifacts\n",
    "\n",
    "The evaluation produces the following outputs:\n",
    "\n",
    "- An evaluated parameter table containing all regression coefficients and evaluation metrics:\n",
    "\n",
    "data/models/interval_theta_table_evaluated.csv\n",
    "\n",
    "- Regression plots for each interval and each target variable:\n",
    "\n",
    "data/models/plots/\n",
    "\n",
    "This evaluation step confirms the correctness of the manual linear regression implementation and provides a reliable baseline for subsequent fault detection using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8a6e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 4 done (TRAIN only).\n",
      " - Evaluated theta table saved to:\n",
      "    data/models/interval_theta_table_evaluated.csv\n",
      " - Regression plots saved to:\n",
      "    data/models\\plots\n",
      "\n",
      "üìå Evaluated table columns:\n",
      "['interval_id', 'start_work_period', 'end_work_period', 'n_periods', 'scratch_mean_theta0', 'scratch_mean_theta1', 'scratch_peak_theta0', 'scratch_peak_theta1', 'sklearn_mean_theta0', 'sklearn_mean_theta1', 'sklearn_peak_theta0', 'sklearn_peak_theta1', 'learning_rate', 'iterations', 'target_space', 'scratch_mean_rmse', 'scratch_mean_mae', 'scratch_mean_r2', 'sklearn_mean_rmse', 'sklearn_mean_mae', 'sklearn_mean_r2', 'scratch_peak_rmse', 'scratch_peak_mae', 'scratch_peak_r2', 'sklearn_peak_rmse', 'sklearn_peak_mae', 'sklearn_peak_r2']\n",
      "\n",
      "üìå Evaluated table first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_id</th>\n",
       "      <th>start_work_period</th>\n",
       "      <th>end_work_period</th>\n",
       "      <th>n_periods</th>\n",
       "      <th>scratch_mean_theta0</th>\n",
       "      <th>scratch_mean_theta1</th>\n",
       "      <th>scratch_peak_theta0</th>\n",
       "      <th>scratch_peak_theta1</th>\n",
       "      <th>sklearn_mean_theta0</th>\n",
       "      <th>sklearn_mean_theta1</th>\n",
       "      <th>...</th>\n",
       "      <th>scratch_mean_r2</th>\n",
       "      <th>sklearn_mean_rmse</th>\n",
       "      <th>sklearn_mean_mae</th>\n",
       "      <th>sklearn_mean_r2</th>\n",
       "      <th>scratch_peak_rmse</th>\n",
       "      <th>scratch_peak_mae</th>\n",
       "      <th>scratch_peak_r2</th>\n",
       "      <th>sklearn_peak_rmse</th>\n",
       "      <th>sklearn_peak_mae</th>\n",
       "      <th>sklearn_peak_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.890499</td>\n",
       "      <td>0.100110</td>\n",
       "      <td>-0.975986</td>\n",
       "      <td>0.075420</td>\n",
       "      <td>-0.890499</td>\n",
       "      <td>0.100110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110413</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>0.623497</td>\n",
       "      <td>0.110413</td>\n",
       "      <td>0.527050</td>\n",
       "      <td>0.438581</td>\n",
       "      <td>0.144521</td>\n",
       "      <td>0.527050</td>\n",
       "      <td>0.438581</td>\n",
       "      <td>0.144521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>3.687289</td>\n",
       "      <td>-0.092567</td>\n",
       "      <td>5.146264</td>\n",
       "      <td>-0.128380</td>\n",
       "      <td>3.687289</td>\n",
       "      <td>-0.092567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066141</td>\n",
       "      <td>0.999061</td>\n",
       "      <td>0.799798</td>\n",
       "      <td>0.066141</td>\n",
       "      <td>1.339267</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>1.339267</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>0.070466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.934994</td>\n",
       "      <td>0.149576</td>\n",
       "      <td>-6.466034</td>\n",
       "      <td>0.124693</td>\n",
       "      <td>-7.934994</td>\n",
       "      <td>0.149576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229123</td>\n",
       "      <td>0.788036</td>\n",
       "      <td>0.709481</td>\n",
       "      <td>0.229123</td>\n",
       "      <td>0.711320</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.202244</td>\n",
       "      <td>0.711320</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.202244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.381330</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>-3.109910</td>\n",
       "      <td>0.051936</td>\n",
       "      <td>-1.381330</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>0.532065</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.834637</td>\n",
       "      <td>0.739091</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.834637</td>\n",
       "      <td>0.739091</td>\n",
       "      <td>0.030956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>8.836954</td>\n",
       "      <td>-0.118015</td>\n",
       "      <td>15.307592</td>\n",
       "      <td>-0.196919</td>\n",
       "      <td>8.836954</td>\n",
       "      <td>-0.118015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119751</td>\n",
       "      <td>0.919026</td>\n",
       "      <td>0.699048</td>\n",
       "      <td>0.119751</td>\n",
       "      <td>1.255306</td>\n",
       "      <td>1.008789</td>\n",
       "      <td>0.168756</td>\n",
       "      <td>1.255306</td>\n",
       "      <td>1.008789</td>\n",
       "      <td>0.168756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   interval_id  start_work_period  end_work_period  n_periods  \\\n",
       "0            2                 11               20         10   \n",
       "1            4                 31               40         10   \n",
       "2            6                 51               60         10   \n",
       "3            7                 61               70         10   \n",
       "4            8                 71               80         10   \n",
       "\n",
       "   scratch_mean_theta0  scratch_mean_theta1  scratch_peak_theta0  \\\n",
       "0            -0.890499             0.100110            -0.975986   \n",
       "1             3.687289            -0.092567             5.146264   \n",
       "2            -7.934994             0.149576            -6.466034   \n",
       "3            -1.381330             0.026113            -3.109910   \n",
       "4             8.836954            -0.118015            15.307592   \n",
       "\n",
       "   scratch_peak_theta1  sklearn_mean_theta0  sklearn_mean_theta1  ...  \\\n",
       "0             0.075420            -0.890499             0.100110  ...   \n",
       "1            -0.128380             3.687289            -0.092567  ...   \n",
       "2             0.124693            -7.934994             0.149576  ...   \n",
       "3             0.051936            -1.381330             0.026113  ...   \n",
       "4            -0.196919             8.836954            -0.118015  ...   \n",
       "\n",
       "   scratch_mean_r2  sklearn_mean_rmse  sklearn_mean_mae  sklearn_mean_r2  \\\n",
       "0         0.110413           0.816184          0.623497         0.110413   \n",
       "1         0.066141           0.999061          0.799798         0.066141   \n",
       "2         0.229123           0.788036          0.709481         0.229123   \n",
       "3         0.014724           0.613534          0.532065         0.014724   \n",
       "4         0.119751           0.919026          0.699048         0.119751   \n",
       "\n",
       "  scratch_peak_rmse  scratch_peak_mae  scratch_peak_r2  sklearn_peak_rmse  \\\n",
       "0          0.527050          0.438581         0.144521           0.527050   \n",
       "1          1.339267          1.074924         0.070466           1.339267   \n",
       "2          0.711320          0.507041         0.202244           0.711320   \n",
       "3          0.834637          0.739091         0.030956           0.834637   \n",
       "4          1.255306          1.008789         0.168756           1.255306   \n",
       "\n",
       "   sklearn_peak_mae  sklearn_peak_r2  \n",
       "0          0.438581         0.144521  \n",
       "1          1.074924         0.070466  \n",
       "2          0.507041         0.202244  \n",
       "3          0.739091         0.030956  \n",
       "4          1.008789         0.168756  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Step 4: Model Evaluation (TRAIN only)\n",
    "#\n",
    "# For each detection interval (interval_id):\n",
    "#   - Compute RMSE, MAE, R^2\n",
    "#   - Compare:\n",
    "#       * From-scratch Linear Regression\n",
    "#       * scikit-learn Linear Regression\n",
    "#   - Visualize regression line vs. data points\n",
    "#\n",
    "# Input:\n",
    "#   data/preprocessed/RMBR4-2_export_preprocessed_train.csv\n",
    "#   data/models/interval_theta_table.csv\n",
    "#\n",
    "# Output:\n",
    "#   data/models/interval_theta_table_evaluated.csv\n",
    "#   data/models/plots/*.png\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# If notebook is in /notebooks, move to project root\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Load config\n",
    "with open(\"configs/experiment_config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "from src.evaluation import evaluate_all_intervals\n",
    "\n",
    "# Run evaluation (TRAIN only)\n",
    "evaluated_df = evaluate_all_intervals(config)\n",
    "\n",
    "print(\"‚úÖ Step 4 done (TRAIN only).\")\n",
    "print(\" - Evaluated theta table saved to:\")\n",
    "print(\"   \", config[\"paths\"][\"evaluated_csv\"])\n",
    "print(\" - Regression plots saved to:\")\n",
    "print(\"   \", os.path.join(config[\"paths\"][\"models_dir\"], \"plots\"))\n",
    "\n",
    "# Inspect results\n",
    "print(\"\\nüìå Evaluated table columns:\")\n",
    "print(evaluated_df.columns.tolist())\n",
    "\n",
    "print(\"\\nüìå Evaluated table first 5 rows:\")\n",
    "display(evaluated_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18059830",
   "metadata": {},
   "source": [
    "### üîπ After Session 1 (Homework)\n",
    "\n",
    "- Refactor your notebook into **modular Python scripts**:  \n",
    "  - `data_loader.py` ‚Äì functions to load data from CSV, API, and DB.  \n",
    "  - `preprocessing.py` ‚Äì cleaning, normalization, train/test split.  \n",
    "  - `model.py` ‚Äì regression model implementations.  \n",
    "  - `evaluation.py` ‚Äì metrics, plots, reporting.  \n",
    "- Ensure each module can run independently.  \n",
    "\n",
    "üí° This will prepare you for **Session 2 (MLOps)**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce0f6c",
   "metadata": {},
   "source": [
    "### üîπ Before Session 2: Preparing for MLOps\n",
    "\n",
    "- Replicate the structure, files and resources that you developed during the **DataStreamVisualization_Workshop**\n",
    "- Use it to organize this project into a folder structure like:\n",
    "\n",
    "```txt\n",
    "linear_regression_project/\n",
    "‚îÇ‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ processed/\n",
    "‚îÇ‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ linear_regression.ipynb\n",
    "‚îÇ‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py\n",
    "‚îÇ‚îÄ‚îÄ configs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ experiment_config.yaml\n",
    "‚îÇ‚îÄ‚îÄ experiments/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ results.csv\n",
    "‚îÇ‚îÄ‚îÄ requirements.txt\n",
    "‚îÇ‚îÄ‚îÄ README.md\n",
    "````\n",
    "\n",
    "* Create a **YAML config file** with parameters:\n",
    "\n",
    "  * Data source path/API endpoint/DB connection string\n",
    "  * Learning rate, iterations, train/test split ratio\n",
    "  * Feature to use as predictor\n",
    "\n",
    "* Document how to run your scripts step-by-step.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84406ab3",
   "metadata": {},
   "source": [
    "### üîπ During Session 2: MLOps Architecture\n",
    "\n",
    "* Apply the **Robot PM MLOps design patterns**:\n",
    "\n",
    "  * **Separation of concerns**: Each module is independent.\n",
    "  * **Configuration-driven**: Experiments are parameterized by configs, not hard-coded values.\n",
    "  * **Experiment tracking**: Save model performance metrics in `experiments/results.csv`.\n",
    "  * **Reproducibility**: Ensure anyone can re-run your experiment with the same results.\n",
    "\n",
    "* Discuss:\n",
    "\n",
    "  * Why modularity matters for ML projects.\n",
    "  * How config management avoids errors in scaling ML experiments.\n",
    "  * How this workflow connects to real-world ML pipelines.\n",
    "\n",
    "üí° **Deliverable during Session 2**:\n",
    "\n",
    "* A structured project with modular code, configs, and experiment tracking.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb0248",
   "metadata": {},
   "source": [
    "## Alert Detection on Test Data\n",
    "\n",
    "In this step, alert thresholds are derived from the training data, and the trained regression model is applied to the test data to identify abnormal detection intervals.\n",
    "\n",
    "The alerting process is divided into two stages:\n",
    "\n",
    "Threshold Estimation (from TRAIN data)\n",
    "\n",
    "Alert Generation (on TEST data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6be15",
   "metadata": {},
   "source": [
    "### Derive Alert Thresholds from Training Data\n",
    "\n",
    "We first compute robust alert thresholds using the training period-level data and the interval-level regression slopes obtained during model training.\n",
    "\n",
    "The following thresholds are estimated:\n",
    "\n",
    "Mean force level threshold\n",
    "\n",
    "Peak force level threshold\n",
    "\n",
    "Mean force slope threshold\n",
    "\n",
    "Peak force slope threshold\n",
    "\n",
    "All thresholds are computed using median + k √ó MAD, ensuring robustness to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66a1425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_alert_threshold': 4.007271646191534,\n",
       " 'peak_alert_threshold': 9.800767286249997,\n",
       " 'mean_slope_threshold': 0.22846773206773197,\n",
       " 'peak_slope_threshold': 0.23366951831779592,\n",
       " 'slope_source': 'sklearn',\n",
       " 'k': 2.5,\n",
       " 'mean_slope_col': 'sklearn_mean_theta1',\n",
       " 'peak_slope_col': 'sklearn_peak_theta1',\n",
       " 'train_csv': 'data/preprocessed/RMBR4-2_export_preprocessed_train.csv',\n",
       " 'theta_csv': 'data/models/interval_theta_table.csv'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.thresholds import fit_thresholds_on_train\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1: (Optional sanity check)\n",
    "# Load the trained interval-level theta table.\n",
    "# This table was generated during model training (TRAIN only)\n",
    "# and contains regression slopes for each interval.\n",
    "# ---------------------------------------------------------\n",
    "theta_df = pd.read_csv(config[\"paths\"][\"theta_table_csv\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: Derive robust alert thresholds using TRAIN data only\n",
    "#\n",
    "# This function:\n",
    "#   - Loads the preprocessed TRAIN period-level CSV\n",
    "#   - Loads the TRAIN interval-level regression slopes (theta table)\n",
    "#   - Computes robust thresholds using:\n",
    "#         threshold = median + k * MAD\n",
    "#   - Saves all thresholds to a single-row CSV file\n",
    "#   - Returns the thresholds as a dictionary\n",
    "#\n",
    "# IMPORTANT:\n",
    "#   - Only TRAIN data is used (prevents data leakage)\n",
    "#   - The same thresholds will later be applied to TEST data\n",
    "# ---------------------------------------------------------\n",
    "thresholds = fit_thresholds_on_train(config)\n",
    "\n",
    "# Display the computed thresholds\n",
    "thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea56db",
   "metadata": {},
   "source": [
    "## Generate Alerts on Test Data\n",
    "\n",
    "Next, the alert logic is applied to the test dataset.\n",
    "Only detection intervals that satisfy both:\n",
    "\n",
    "Trend-based condition (slope exceeds threshold), and\n",
    "\n",
    "Level-based condition (mean or peak exceeds threshold)\n",
    "\n",
    "are reported as anomalies.\n",
    "\n",
    "If no abnormal intervals are detected, an empty results file is generated and the system reports that no faults were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c8d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No anomalies detected. Wrote empty results file: experiments/results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_id</th>\n",
       "      <th>start_work_period</th>\n",
       "      <th>end_work_period</th>\n",
       "      <th>interval_start_time</th>\n",
       "      <th>interval_end_time</th>\n",
       "      <th>predicted_failure_time</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>alert_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [interval_id, start_work_period, end_work_period, interval_start_time, interval_end_time, predicted_failure_time, failure_type, alert_reason]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.alerts import detect_alerts_on_test\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: Generate alerts on TEST data\n",
    "#\n",
    "# In this step, the alert detection logic is applied to\n",
    "# the TEST dataset only.\n",
    "#\n",
    "# IMPORTANT:\n",
    "#   - Thresholds were derived from TRAIN data in Step 1\n",
    "#   - No statistics are re-computed on TEST data\n",
    "#   - This prevents data leakage\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Ensure the TEST preprocessed period-level CSV is used\n",
    "# ---------------------------------------------------------\n",
    "config[\"paths\"][\"preprocessed_test_csv\"] = config[\"paths\"][\"preprocessed_test_csv\"]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Run alert detection on TEST data\n",
    "#\n",
    "# This function:\n",
    "#   - Loads TEST period-level data\n",
    "#   - Aggregates periods into interval-level summaries\n",
    "#   - Loads TRAIN-derived alert thresholds\n",
    "#   - Loads TRAIN regression slopes (theta table)\n",
    "#   - Applies alert logic:\n",
    "#       * Trend condition: |slope| > slope threshold\n",
    "#       * Level condition: mean or peak > level threshold\n",
    "#   - Reports only anomalous intervals\n",
    "#\n",
    "# If no anomalies are detected:\n",
    "#   - An empty CSV file (headers only) is written\n",
    "#   - A message is printed indicating no faults were found\n",
    "# ---------------------------------------------------------\n",
    "results_df = detect_alerts_on_test(config)\n",
    "\n",
    "# Display detected anomalies (may be empty)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145dabc",
   "metadata": {},
   "source": [
    "### üîπ After Session 2: Extension & Homework\n",
    "\n",
    "0. **Submission Format**  \n",
    "   - This activity is **to be submitted individually**. Each student must create and manage their own project repository.\n",
    "\n",
    "1. **Workshop Replication**  \n",
    "   - This workshop is modeled on the structure, files, and resources used in the **DataStreamVisualization_Workshop**.  \n",
    "   - Your submission must replicate this style of organization and completeness.  \n",
    "\n",
    "2. **Repository Submission Instructions**  \n",
    "   - Create a **remote Git repository** named:  \n",
    "     ```\n",
    "     LinearRegressionArchitecture_Workshop\n",
    "     ```\n",
    "   - Once your repository is ready, send your instructor an email with the subject line:  \n",
    "     ```\n",
    "     Linear Regression Architecture Workshop\n",
    "     ```\n",
    "   - In the body of the email, paste the **full URL of your repository**, making sure it ends with the `.git` extension.  \n",
    "     - ‚úÖ Correct example: `https://github.com/username/LinearRegressionArchitecture_Workshop.git`  \n",
    "     - ‚ùå Incorrect example: `https://github.com/username/LinearRegressionArchitecture_Workshop`\n",
    "\n",
    "3. **Repository Requirements**  \n",
    "   Your repository must contain:  \n",
    "   - A **frozen version of the codebase** (no further modifications after submission).  \n",
    "   - A `requirements.txt` file that lists all dependencies required to run your project.  \n",
    "   - A `README.md` file that:  \n",
    "     - Displays the title: **Linear Regression Architecture Workshop**.  \n",
    "     - Describes the work completed in the workshop.  \n",
    "     - Summarizes key design decisions.  \n",
    "\n",
    "4. **Notebook Updates (RobotPM_MLOps.ipynb)**  \n",
    "   - Open the notebook `RobotPM_MLOps.ipynb`.  \n",
    "   - Update it so that it highlights all changes made to the original project architecture and files.  \n",
    "   - Specifically, reference the lists provided in the notebook:  \n",
    "     - **Recommended Additions**  \n",
    "     - **Recommended Enhancements**  \n",
    "     - **Breakdown examples** (from both design breakdown sections).  \n",
    "\n",
    "5. **Expectations for Notebook Updates**  \n",
    "   - You are **not required to fully implement** the changes and updates at this stage.  \n",
    "   - Instead, create all **placeholders, stubs, and structure** needed to prepare the project for a future code review.  \n",
    "   - Think of this as **project scaffolding** for the upcoming implementation sprint cycle, which will be executed in a future project.  \n",
    "\n",
    "üí° **Final Deliverable**:  \n",
    "- A complete GitHub repository named `LinearRegressionArchitecture_Workshop` with the required structure, files, and documentation.  \n",
    "- An updated `RobotPM_MLOps.ipynb` notebook showing how the project architecture was extended and prepared for enhancements.  \n",
    "- Email submission to the instructor containing the `.git` repository URL.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
